---
title: "URJC MDS TFM - Financial Credit Risk"
author: "Miguel García Sánchez"
date: "`r Sys.Date()`"
output:
 html_document:
  code_folding: hide
  toc: yes
  toc_float: TRUE
  toc_depth: 3 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

# *INICIO DEL DESARROLLO DEL TRABAJO*

# 1. Introducción 

El trabajo a desarrollar consiste en el análisis de un dataset relativo a datos de préstamos de entidades financieras, donde se quiere tratar de comprender cuales son las razones y características que llevan al llamado "default" o situación de impago, así como modelos que pueden ayudar a predecirlo.

## 1.1. Desarrollo, programación y control de versiones

Se ha elegido para el desarrollo de una parte del trabajo el lenguaje de programación R (R version 4.2.2), cómo IDE de desarrollo RStudio (RStudio version 2022.12.0.353) y cómo herramienta de control de versiones GitHub (proyecto "/MDS_TFM" creado y vinculado al usuario Miguel_gs - "mgarciasanc2021"). 

**Link del proyecto en GitHub:** 
https://github.com/mgarciasanc2021/MDS_TFM

## 1.2. Paquetes R

```{r librerias, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
library(formatR)
library(readr)
library(ggplot2)
library(GGally)
library(dplyr)
library(tidyr)
library(missForest)
library(VIM)
library(formattable)
library(usmap)
library(cowplot)
library(corrplot)
library(MASS)
library(ggfortify)
library(nortest)
library(car)
library(lmtest)
library(PerformanceAnalytics)
library(Amelia)
library(ggthemes)
library(tidyverse)
library(tibble)
library(gridExtra)
#library(ggbiplot)
library(factoextra)
library(caret)
library(ISLR)
library(rpart)
library(rpart.plot)
library(rattle)
library(tsne)
library(Rtsne)
library(class)
library(ada)
library(factoextra)
library(cluster)
library(useful)
library(mgcv)
library(xgboost)
library(randomForest)
library(kernlab)
library(pROC)
#library(doMC)
library(ggpubr)
library(ROCR)
#library(ggextra)

```

# 2. Conjunto de datos

El conjunto de datos elegido para el desarrollo del trabajo es "Credit Risk Dataset". Este dataset incluye información de clientes y préstamos contratados por estos en diferentes instituciones financiera.

**Link del data set:** <https://www.kaggle.com/datasets/laotse/credit-risk-dataset>.

## 2.1. Carga de los datos

El conjunto de datos "Credit Risk Dataset" contiene 12 columnas y 32.581 filas y lo obtenemos en formato .CSV. 

Inicialmente se han guardado los datos en un data frame llamado "fin_credrisk" y se ha realizado un estudio inicial sobre su contenido utilizando la función head y summary.

```{r cargas datos, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fin_credrisk<- read_csv("financial_credit_risk.csv")
head(fin_credrisk)
count(fin_credrisk)

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
summary(fin_credrisk)

```

Sacando estos datos vemos algunas cosas importantes a comentar:

* La variable "person_age" tiene un valor máximo de 144 años.
* La variable "person_emp_length" tiene un valor máximo de 123 años.
* La variable "person_emp_length" tiene 895 registros con NAs.
* La variable "loan_interest_rate" tiene 3.116 registros con NAs.

## 2.2. Definición de las variables

Empezando ya el análisis inicial del conjunto de datos que tenemos, vemos que las 12 variables que componen los datos pueden ser descritas como:

**Input variables o Variables de entrada/predictoras:**

* **person_age:** Edad de la persona que toma el crédito.
* **person_income:** Ingresos anuales en dólares de la persona que toma el crédito.
* **person_home_ownership:** Estado de la propiedad de la vivienda donde reside la persona que toma el crédito.
* **person_emp_length:** Periodo de tiempo en años desde que la persona que toma el crédito está en situación laboral activa.
* **loan_intent:** Uso del crédito concedido.
* **loan_grade:** Calidad crediticia del crédito concedido.
* **loan_amnt:** Cantidad en dólares de crédito concedido.
* **loan_int_rate:** Tipo de interés en porcentaje del crédito concedido. 
* **loan_percent_income:** Porcentaje de lo que supone el préstamo sobre los ingresos anuales en dólares de la persona que toma el crédito.
* **cb_person_default_on_file:** Variable binaria que indica si la persona tomadora del crédito ha tenido antes una situación de impago o no.
* **cb_preson_cred_hist_length:** Duración en años del historial crediticio de la persona tomadora del crédito.

**Output variable o Variable de salida/respuesta/objetivo:**

* **loan_status:** Estado actual del crédito (suponiendo "1" como impagado o situación de default, y "0" no impagado)

## 2.3. Objetivo del análisis

El objetivo final del proyecto es conseguir llegar a un modelo que permita predecir el riesgo de impago o "default" que puede tener en cartera una institución financiera y saber si estamos ante créditos que van a poder ser devueltos por el cliente, o por si el contrario se van a quedar como impagados.

# *ANÁLISIS INICIAL, LIMPIEZA Y PARTICIONADO DE LOS DATOS*

# 3. Limpieza inicial del conjunto de datos

## 3.1. Cambio de nombres de las columnas

Se ha decidido no realizar un cambio en el nombre de las variables que aparecen en las columnas de los datos, ya que ya se sigue un patrón de nombre sin espaciones y así no tendremos problemas con ello a futuro.

## 3.2. Cambio de tipo de variable de las columnas

Vemos que en el dataset tenemos variables de tipo numéricas (num - col_double()) y de tipo texto o cadena de caractéres (chr - col_character()).

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
str(fin_credrisk)

```

Se ha decidido por ello realizar cambio en el tipo de variable de las que son cadena de caracter y pasarlas a variables categóricas.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fin_credrisk$person_home_ownership = as.factor(gsub("\\$",
    "", fin_credrisk$person_home_ownership))

fin_credrisk$loan_intent = as.factor(gsub("\\$",
    "", fin_credrisk$loan_intent))

fin_credrisk$loan_grade = as.factor(gsub("\\$",
    "", fin_credrisk$loan_grade))

fin_credrisk$cb_person_default_on_file = as.factor(gsub("\\$",
    "", fin_credrisk$cb_person_default_on_file))

```

Vemos que con el cambio tenemos en el dataset variables de tipo numéricas y categóricas

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
str(fin_credrisk)

```

Cabría la posibilidad de tratar de transformar la variable "loan_status"en categórica en función de si estamos ante préstamos de crédito impagados ("default") o no.

# 4. Análisis preliminar del conjunto de datos

## 4.1. Análisis de datos faltantes

Analizamos en mayor profundidad lo detectado anteriomente respecto a datos faltantes en el dataset:

* La variable "person_emp_length" tiene 895 registros con NAs.
* La variable "loan_interest_rate" tiene 3.116 registros con NAs.

Haciendo uso de la librería VIM y de la librería Amelia, analizamos la estructura que tienen los datos faltantes dentro de nuestro data set para ver y entender como se distribuyen y a que variables afecta. 

Se puede comprobar que la proporción de datos faltantes es de aproximadamente un 1%. Hay 895 observaciones con datos faltantes en la variable "person_emp_length" y 3.116 observaciones con datos faltantes en "loan_int_rate".

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
summary(aggr(fin_credrisk,numbers=T,sortVar=T))

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
missmap(fin_credrisk, main="Missing Map")

```

### 4.1.2. Tratamiento e imputación de datos faltantes

Para la imputación de datos faltantes en las columnas "person_emp_length" y "loan_int_rate", se ha decidido reemplazar todos sus NAs según los valores medianos de las mismas variables a las que se referencian.

Con la función summary se comprueba que ya no hay más datos faltantes en el data set.

```{r imputacion, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fin_credrisk$person_emp_length[is.na(fin_credrisk$person_emp_length)]<-median(fin_credrisk$person_emp_length,na.rm = TRUE)
fin_credrisk$loan_int_rate[is.na(fin_credrisk$loan_int_rate)]<-median(fin_credrisk$loan_int_rate,na.rm = TRUE)

summary(fin_credrisk)

```

## 4.2. Análisis de datos atípico o outliers

Analizamos en mayor profundidad lo detectado anteriomente respecto a datos atípico en el dataset:

* La variable "person_age" tiene un valor máximo de 144 años.
* La variable "person_emp_length" tiene un valor máximo de 123 años.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
plot(fin_credrisk$person_age, fin_credrisk$person_emp_length)

```

Vemos como hay algunos datos que si podemos considerar atípico. Hay dos registros con un historial laboral de la persona contratante del préstamo ("person_emp_length") de más de 120 años y 4 registros con una edad de la persona contratante del préstamo ("person_age") superior a 120 años. 

### 4.2.2. Tratamiento y eliminación de datos atípicos o outliers

Estos caso comentados son raros e ilógicos, y optamos finalmente por eliminarlos del dataset.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fin_credrisk <- fin_credrisk %>%
   filter(person_age < 120) %>%
   filter(person_emp_length < 120)

```


Mostramos el resultado de como queda ahora el dataset con esta modificación. Ya no tenemos ni atípico ni datos faltantes en el dataset. Ahora el dateset mantiene las 12 columnas, pero pasamos a tener 32.574 filas o registros.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
summary(fin_credrisk)

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
count(fin_credrisk)

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
plot(fin_credrisk$person_age, fin_credrisk$person_emp_length)

```

# 5. Partición del conjunto de datos: data set training y data set test

Una vez vistos por encima la estructura general de los datos, pasamos a dividir el conjunto de datos en dos para diferenciar los que usaremos de entrenamiento de los que usaremos de test (viendo la cantidad de datos de la que disponemos, la distribución elegida ha sido: 20% test y 80% training). Establecemos una semilla que nos guarde de forma permanente la división que hacemos para que la distribución de los datos sea siempre la misma.

Guardamos además la partición de datos de test para ser utilizada a futuro para la validación del modelo final y pasamos a trabajar de aquí en adelante con la partición de training.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
set.seed(101)

sample <- sample.int(n=nrow(fin_credrisk), size=floor(.80*nrow(fin_credrisk)), replace = F)
fcr_train <- fin_credrisk[sample,]
fcr_test <- fin_credrisk[-sample,]
fcr_train
fcr_test

```

# *ANÁLISIS EN PROFUNDIDAD DE LOS DATOS*

# 6. EDA - Análisis exploratorio de datos

## 6.1. Análisis de la distribución de las variables

Analizamos como se distribuyen las diferentes variables de entrada de nuestro dataset:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train %>%
    keep(is.numeric) %>%
    gather() %>%
    ggplot(aes(value, fill = key)) + facet_wrap(~key, scales = "free") +
    geom_histogram(bins = sqrt(nrow(fcr_train))) + theme(legend.position = "none")

```

* **Variables numéricas relativas a la persona**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
ga <- fcr_train %>%
    ggplot(aes(x = person_age)) + geom_histogram(bins =20,
    fill = "#619CFF")

gb <- fcr_train %>%
    ggplot(aes(x = person_income)) + geom_histogram(bins = 20,
    fill = "#E58700") + theme(axis.text.x = element_text(angle = 10, hjust = 0.5, vjust = 0.5))

gd <- fcr_train %>%
    ggplot(aes(x = person_emp_length)) + geom_histogram(bins = 20,
    fill = "#FD61D1")

gl <- fcr_train %>%
    ggplot(aes(x = cb_person_cred_hist_length)) + geom_histogram(bins = 20,
    fill = "#CDAD00")

grid.arrange(ga, gb, gd, gl)

```

- Modificamos a logaritmos??

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#fcr_train <- fcr_train %>%
 #   mutate(Log_person_age = log(person_age), Log_person_income = log(person_income),
  #      Log_person_emp_length = log(person_emp_length), Log_cb_person_cred_hist_length = #log(cb_person_cred_hist_length))

#ga <- fcr_train %>%
    #ggplot(aes(x = Log_person_age)) + geom_histogram(bins = 20,
    #fill = "#619CFF")

#gb <- fcr_train %>%
    #ggplot(aes(x = Log_person_income)) + geom_histogram(bins = 20,
    #fill = "#E58700") + theme(axis.text.x = element_text(angle = 10, hjust = 0.5, vjust = 0.5))

#gd <- fcr_train %>%
    #ggplot(aes(x = Log_person_emp_length)) + geom_histogram(bins = 20,
    #fill = "#FD61D1")

#gl <- fcr_train %>%
    #ggplot(aes(x = Log_cb_person_cred_hist_length)) + geom_histogram(bins = 20,
    #fill = "#CDAD00")

#grid.arrange(ga, gb, gd, gl)

```

* **Variables numéricas relativas al préstamo**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
gg <- fcr_train %>%
    ggplot(aes(x = loan_amnt)) + geom_histogram(bins = 20,
    fill = "#8B2323")

gh <- fcr_train %>%
    ggplot(aes(x = loan_int_rate)) + geom_histogram(bins = 20,
    fill = "#00008B")

gj <- fcr_train %>%
    ggplot(aes(x = loan_percent_income)) + geom_histogram(bins = 20,
    fill = "#7FFF00")

grid.arrange(gg, gh, gj)

```

- Modificamos a logaritmos??

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
#fcr_train <- fcr_train %>%
    #mutate(Log_loan_amnt = log(loan_amnt), Log_loan_int_rate = log(loan_int_rate),
       #Log_loan_percent_income = log(loan_percent_income))

#gg <- fcr_train %>%
    #ggplot(aes(x = Log_loan_amnt)) + geom_histogram(bins = 20,
    #fill = "#8B2323")

#gh <- fcr_train %>%
    #ggplot(aes(x = Log_loan_int_rate)) + geom_histogram(bins = 20,
    #fill = "#00008B")

#gj <- fcr_train %>%
    #ggplot(aes(x = Log_loan_percent_income)) + geom_histogram(bins = 20,
    #fill = "#7FFF00")

#grid.arrange(gg, gh, gj)

```

* **Variables categóricas relativas a la persona**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
gc <- fcr_train %>%
    ggplot(aes(x = person_home_ownership)) + geom_histogram(bins = 20,
    fill = "#00CD00", stat="count")

gk <- fcr_train %>%
    ggplot(aes(x = cb_person_default_on_file)) + geom_histogram(bins = 20,
    fill = "#7FFFD4", stat="count")

grid.arrange(gc, gk)

```

* **Variables categóricas relativas al préstamo**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
ge <- fcr_train %>%
    ggplot(aes(x = loan_intent)) + geom_histogram(bins = 20,
    fill = "#B983FF", stat="count") + theme(axis.text.x = element_text(angle = 10, hjust = 0.75, vjust = 0.75))

gf <- fcr_train %>%
    ggplot(aes(x = loan_grade)) + geom_histogram(bins = 20,
    fill = "#FFFF00", stat="count")

grid.arrange(ge, gf)

```

Analizamos como se distribuyen la variable objetivo de nuestro dataset:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
ggplot(data = fcr_train) + geom_bar(mapping = aes(x = loan_status, fill = as.factor(loan_status))) +
    labs(title = "Histograma del estado del crédito")

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
table(fcr_train$loan_status)

```
```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
prop.table(table(fcr_train$loan_status))

```

El 78.15% de los registros en nuestro dataset de train (20.365 registros) tiene valor 0 correspondiente a créditos que no han entrado en default, y el 21.85% (5.694 registros) tienen valor 1 correspondiente a créditos que por el contrario si han sido impagados.

## 6.2. Boxplot - análisis de la variables de relevancia y de los atípicos observados

(LOGARITMOS??)

Analizamos si nuestras variables tienen valores atípicos, cuales son sus valores medios y vemos sus intervalos de confianza, a través de gráficos de tipo Boxplot.

* **Boxplot variable person_age**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
BoxPlot_person_age <- ggplot(fcr_train, aes(x = factor(loan_status), y = person_age)) +
    geom_boxplot() + geom_boxplot(fill = "#619CFF") + ggtitle("Boxplot person_age")
BoxPlot_person_age

```

Se aprecia como la variable "person_age" relativa a la edad del contratante del préstamo se mantiene bastante igual en los casos donde hay default o no hay default.

* **Boxplot variable person_income**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
BoxPlot_person_income <- ggplot(fcr_train, aes(x = factor(loan_status), y = person_income)) +
    geom_boxplot() + geom_boxplot(fill = "#E58700") + ggtitle("Boxplot person_income")
BoxPlot_person_income

```

Se aprecia ligeramente como la variable "person_income" relativa a los ingresos anuales del contratante del préstamo, es inferior en media en los casos donde se da el impago del crédito.

* **Boxplot variable person_emp_length**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
BoxPlot_person_emp_length <- ggplot(fcr_train, aes(x = factor(loan_status), y = person_emp_length)) +
    geom_boxplot() + geom_boxplot(fill = "#FD61D1") + ggtitle("Boxplot person_emp_length")
BoxPlot_person_emp_length

```

Se aprecia ligeramente como la variable "person_emp_length" relativa al periodo de tiempo en años desde que la persona que toma el crédito está en situación laboral activa, es inferior en media en los casos donde se da el impago del crédito.

* **Boxplot variable cb_person_cred_hist_length**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
BoxPlot_cb_person_cred_hist_length <- ggplot(fcr_train, aes(x = factor(loan_status), y = cb_person_cred_hist_length)) + geom_boxplot() + geom_boxplot(fill = "#CDAD00") + ggtitle("Boxplot cb_person_cred_hist_length")
BoxPlot_cb_person_cred_hist_length

```

Se aprecia como la variable "person_cred_hist_length" relativa a la duración en años del historial crediticio de la persona tomadora del crédito, se mantiene bastante igual en los casos donde hay default o no hay default.

* **Boxplot variable loan_amnt**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
BoxPlot_loan_amnt <- ggplot(fcr_train, aes(x = factor(loan_status), y = loan_amnt)) +
    geom_boxplot() + geom_boxplot(fill = "#8B2323") + ggtitle("Boxplot loan_amnt")
BoxPlot_loan_amnt

```

Se aprecia como la variable "loan_amount" relativa a la cantidad en dólares de crédito concedido, es superior en media en los casos donde se da el impago del crédito.

* **Boxplot variable loan_int_rate**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
BoxPlot_loan_int_rate <- ggplot(fcr_train, aes(x = factor(loan_status), y = loan_int_rate)) +
    geom_boxplot() + geom_boxplot(fill = "#00008B") + ggtitle("Boxplot loan_int_rate")
BoxPlot_loan_int_rate

```

Se aprecia como la variable "loan_int_rate" relativa al tipo de interés en porcentaje del crédito concedido, es superior en media en los casos donde se da el impago del crédito.

* **Boxplot variable loan_percent_income**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
BoxPlot_loan_percent_income <- ggplot(fcr_train, aes(x = factor(loan_status), y = loan_percent_income)) +
    geom_boxplot() + geom_boxplot(fill = "#7FFF00") + ggtitle("Boxplot loan_percent_income")
BoxPlot_loan_percent_income

```

Se aprecia como la variable "loan_percent_income" relativa al porcentaje de lo que supone el préstamo sobre los ingresos anuales en dólares de la persona que toma el crédito, es superior en media en los casos donde se da el impago del crédito.


Como conclusión lógica de todo esto, normalmente el la situación de impago es más frecuente en personas con ingresos más bajos, menor número de años de actividad laboral y con préstamos de cantidades más altas y con tipos de interés elevados.

## 6.3. Correlación entre variables

Continuando con en análisis de las distintas variables del data set y el estudio de como se relacionan entre si, queremos ver de forma global como se correlacionan las variables numéricas que nos pueden llegar a servir para el modelo de predicción.

### 6.3.1. Análisis de la correlación global del conjunto de variables

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
corrplot(cor(fcr_train %>%
    mutate(loan_status = as.numeric(loan_status)) %>%
    keep(is.numeric)))
```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
res <- cor(fcr_train %>%
    mutate(loan_status = as.numeric(loan_status)) %>%
    keep(is.numeric))
round(res, 2)

```

Vemos que las variables que más estan correlacionadas con la variable “loan_status” son: “person_income”, “loan_amnt”, “loan_int_rate” y “loan_percent_income”.

### 6.3.2. Análisis de la correlación bivariante

Realizamos un análisis bivariante para ver que variables están más correlacionadas, positva o negativamente, entre si.

* **Correlación: person_age y cb_person_cred_hist_length:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
cor(x = fcr_train$person_age, y = fcr_train$cb_person_cred_hist_length)

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train %>%
    ggplot(aes(person_age, cb_person_cred_hist_length)) + geom_point(alpha = 0.2,
    colour = "green") + geom_smooth(formula = "y ~ x", method = "lm") +
    labs(title = "Relación entre las variables person_age y cb_person_cred_hist_length",
        x = "person_age", y = "cb_person_cred_hist_length")

```

* **Correlación: loan_amnt y person_income:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
cor(x = fcr_train$loan_amnt, y = fcr_train$person_income)

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train %>%
    ggplot(aes(loan_amnt, person_income)) + geom_point(alpha = 0.2,
    colour = "green") + geom_smooth(formula = "y ~ x", method = "lm") +
    labs(title = "Relación entre las variables loan_amnt y person_income",
        x = "loan_amnt", y = "person_income")

```

* **Correlación: loan_percent_income y person_income:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
cor(x = fcr_train$loan_percent_income, y = fcr_train$person_income)

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train %>%
    ggplot(aes(loan_percent_income, person_income)) + geom_point(alpha = 0.2,
    colour = "green") + geom_smooth(formula = "y ~ x", method = "lm") +
    labs(title = "Relación entre las variables loan_percent_income y person_income",
        x = "loan_percent_income", y = "person_income")

```

* **Correlación: loan_percent_income y loan_amnt:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
cor(x = fcr_train$loan_percent_income, y = fcr_train$loan_amnt)

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train %>%
    ggplot(aes(loan_percent_income, loan_amnt)) + geom_point(alpha = 0.2,
    colour = "green") + geom_smooth(formula = "y ~ x", method = "lm") +
    labs(title = "Relación entre las variables loan_percent_income y loan_amnt",
        x = "loan_percent_income", y = "loan_amnt")

```

* **Correlación: loan_status y loan_int_rate:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
cor(x = fcr_train$loan_status, y = fcr_train$loan_int_rate)

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train %>%
    ggplot(aes(loan_status, loan_int_rate)) + geom_point(alpha = 0.2,
    colour = "green") + geom_smooth(formula = "y ~ x", method = "lm") +
    labs(title = "Relación entre las variables loan_status y loan_int_rate",
        x = "loan_status", y = "loan_int_rate")

```

* **Correlación: loan_status y loan_percent_income:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
cor(x = fcr_train$loan_status, y = fcr_train$loan_percent_income)

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train %>%
    ggplot(aes(loan_status, loan_percent_income)) + geom_point(alpha = 0.2,
    colour = "green") + geom_smooth(formula = "y ~ x", method = "lm") +
    labs(title = "Relación entre las variables loan_status y loan_percent_income",
        x = "loan_status", y = "loan_percent_income")

```

## 6.4. Análisis de las variables categóricas

Se realiza un análisis de las variables categóricas en relación con el resto de variables numéricas del dataset. Se trata de entender las características personales de la gente y su actividad creditica para tratar de sacar un cierto análisis preliminar.

* **Variable cb_person_default_on_file en función de las variables loan_int_rate y person_income:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
plot1 <- ggplot(fcr_train, aes(loan_int_rate, loan_percent_income, col=cb_person_default_on_file)) +
  geom_point() + ylab("Loan % income") + xlab("Interest rate") + labs(color = "Previous default: ") +
  theme(legend.position="bottom") 

ggExtra::ggMarginal(plot1, type = "boxplot")

```

Con este gráfico se puede entender que los tipos de interés aplicados por las entidades bancarias en los préstamos que conceden, vienen influidos por si el cliente ha registrado algún impago anterior en su historial crediticio. Además, se ve como el porcentaje de lo que supone el préstamo sobre los ingresos anuales en dólares de la persona que toma el crédito, no es algo definitivo para establecer el tipo de interés que se aplica en la operación.


* **Variable person_home_ownership en función de las variables person_age y person_income:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
plot1 <- ggplot(fcr_train, aes(person_age, person_income, col=person_home_ownership)) +
  geom_point() + ylab("Income") + xlab("Age") + labs(color = "Home ownership: ") +
  theme(legend.position="bottom") 

ggExtra::ggMarginal(plot1, type = "boxplot")

```

En base a este gráfico podemos sacar como conclusión que: existe un sesgo en la edad (el dateset tiene más registros de gente joven), existe un sesgo en los ingresos (el dataset no tiene bien balanceada la variable "person_income", estando está desequilibrada y siendo más frecuente los ingresos bajos) y parece que la gente con hipoteca tiene por lo general más ingresos que la gente que vive de alquiler.

* **Variable loan_intent en función de las variables loan_amnt y loan_int_rate:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
plot2 <- ggplot(fcr_train, aes(loan_amnt, loan_int_rate, col=loan_intent)) +
  geom_point() + ylab("Interest rate") + xlab("Loan Amount") + labs(color = "Loan Intent: ") +
  theme(legend.position="bottom")

ggExtra::ggMarginal(plot2, type = "boxplot")

```

Este segundo gráfico obtenido, representa la relación entre el importe del préstamo solicitado y el tipo de interés aplicado. Aquí podemos ver que no hay una correlación clara entre las dos variables, por lo que podemos decir que no dependen la una de la otra. Además, parece que la intención de préstamo se distribuye por igual en la muestra, lo que significa que la intención no influye en absoluto en los tipos de interés ni en el importe del préstamo. En este caso, las distribuciones son gaussianas normales con un ligero sesgo.

* **Variable loan_grade en función de las variables loan_amnt y person_income:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
plot3 <- ggplot(fcr_train, aes(loan_amnt, person_income, col=loan_grade)) +
  geom_point() + ylab("Income") + labs(color = "Loan Grade: ") + theme(legend.position="bottom") +
  scale_color_manual(values=c("#66cc99", "#70F000", "#D0FF00", "#F3FF0F", "#FFDB4D", "#FFA64D", "#FF4D4D"))

ggExtra::ggMarginal(plot3, type = "boxplot")

```

En este tercer gráfico obtenido, tampoco existe una relación clara entre los ingresos y el importe del préstamo. Al añadir diferentes colores para las calificaciones de los préstamos, observamos una pequeña tendencia a que las personas con ingresos bajos y con un préstamo elevado tengan una calificación más baja. Pero no se aprecia una relación clara.

* **Variable loan_grade en función de las variables person_age y loan_int_rate:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
plot4 <- ggplot(fcr_train, aes(person_age, loan_int_rate, col=loan_grade)) +
  geom_point() + ylab("Interest rate") + xlab("Age") +  labs(color = "Loan Grade: ") +
theme(legend.position="bottom") + scale_color_manual(values=c("#66cc99", "#70F000", "#D0FF00", "#F3FF0F", "#FFDB4D", "#FFA64D", "#FF4D4D"))

ggExtra::ggMarginal(plot4, type = "boxplot")

```

En este cuarto gráfico se muestra la relación entre la edad, el tipo de interés y el grado del préstamo. Aquí podemos ver claramente que la calificación del préstamo depende del tipo de interés, que divide el gráfico en varias secciones. Básicamente dice que cuanto más alto es el tipo de interés, mayor es el riesgo percibido. Esto podría deberse al método de evaluación del grado de riesgo de las personas. Además, observamos que las personas mayores tienden a tener tipos de interés más bajos por término medio que los jóvenes.

## 6.5. Análisis de la variable de interés

Ahora se pasa a analizar nuestra variable de interes "loan_status", para ver la probabilidad de impago de un crédito o préstamo dadas ciertas características en el cliente o en el propio préstamos.

* **Variable loan_status en función de las variables loan_percent_income y loan_int_rate:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
plot5 <- ggplot(fcr_train, aes(loan_percent_income, loan_int_rate, col= factor(loan_status, labels = c("Not default", "Default")))) +
  geom_point() + ylab("Interest rate") + xlab("Loan percent income") + labs(color = "Loan Status: ") + 
  theme(legend.position="bottom") + scale_color_manual(values=c("#66cc99", "#ff3366"))

ggExtra::ggMarginal(plot5, type = "boxplot")

```

En este gráfico se vuelve a considerar el nivel de los tipos de interés, en relación con la proporción entre el importe del préstamo y los ingresos. La forma de los puntos sugiere que no hay una relación clara entre estas dos variables, lo que significa que los tipos de interés no dependen en absoluto del porcentaje de ingresos del préstamo. Sin embargo, cuanto más nos acercamos a un ratio más alto, más bajos son los tipos de interés.

Si analizamos a las personas que han impagado (en rojo) y a las personas que no han impagado (en verde), podemos ver claramente niveles de umbral hacia el 12% para los tipos de interés, y 0,3 para la variable de ingresos porcentuales del préstamo. Esta zona podría considerarse menos arriesgada tanto para los prestamistas como para los prestatarios. Esto parece razonable, ya que unos tipos de interés más altos y una mayor relación ingresos/préstamo significa que es menos probable que la gente reembolse su deuda.Es decir, a mayor nivel de tipo de interés del préstamos y un mayor nivel de endeudamiento en relación a los ingresos, es más probable que un cliente de una entidad bancaria termine por impagar su deuda.

* **Variable loan_status en función de la variable person_home_ownership:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
ggplot(fcr_train, aes(x = factor(loan_status), fill = factor(person_home_ownership))) +
  geom_bar(position = "fill") +
  ylab("Home ownership %") + xlab("Default") + labs(fill = "Type of ownership:") +
  theme(legend.position="top", plot.background = element_rect(colour = "black", size = 1)) + 
  guides(fill = guide_legend(reverse=TRUE)) +
  coord_flip()

```

Con este gráfico se muestran las frecuencias absolutas del tipo de propiedad de la vivienda con respecto a las personas que han incurrido en impago del crédito. Se puede observar que típicamente quien paga un alquiler es más propenso al impago considerando todas las demás clases.

* **Variable loan_status en función de la variable loan_intent:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
ggplot(fcr_train, aes(x = factor(loan_status), fill = factor(loan_intent))) +
  geom_bar(position = "fill") +
  ylab("Loan Intent") + xlab("Credit Default") + labs(fill = "Loan intent:") +
  theme(legend.position="top", plot.background = element_rect(colour = "black", size = 1)) + 
  guides(fill = guide_legend(reverse=TRUE)) +
  coord_flip()

```

Con este gráfico se pasa a comparar a las personas que han incumplido con el pago del préstamo y las que no, con la finalidad del préstamo solicitado. Como hemos señalado antes, la variable de la finalidad del préstamo está bien distribuida, sin embargo, cuando el préstamo se dedica a la consolidación de deudas y con fines médicos, parece más probable que se produzca un impago de la deuda.

* **Variable loan_status en función de la variable loan_grade:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
ggplot(fcr_train, aes(x = factor(loan_status), fill = factor(loan_grade))) +
  geom_bar(position = "fill") + scale_fill_manual(values=c("#66cc99", "#70F000", "#D0FF00", "#F3FF0F", "#FFDB4D", "#FFA64D", "#FF4D4D")) +
  ylab("Loan Grade") + xlab("Credit Default") + labs(fill = "Loan grade:") +
  theme(legend.position="top", plot.background = element_rect(colour = "black", size = 1)) + 
  guides(fill = guide_legend(reverse=TRUE)) +
  coord_flip()

```

Utilizando de nuevo la paleta de colores para el grado de riesgo, es posible observar que esta variable tiene cierto poder predictivo de los impagos de los tomadores de crédito. Según los datos, cuando el grado de riesgo es más bajo (calificación crediticia "A"), es menos probable que se produzca un impago. Lo contrario ocurre con los grados inferiores ("D", "E", "F" y "G")..

* **Variable loan_status en función de las variables loan_int_rate, person_income y loan_amnt:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
g1 <- ggplot(fcr_train, aes(x = factor(loan_status), y = loan_int_rate)) + 
  geom_boxplot(fill = "orange", alpha = 0.2) +
  ylab("Interest rate") + xlab("Credit Default") +
  coord_flip() 

g2 <- ggplot(fcr_train, aes(x = factor(loan_status), y = person_income)) + 
  geom_boxplot(fill = "orange", alpha = 0.2) +
  ylab("Income") + xlab("Credit Default") +
  coord_flip() 

g3 <- ggplot(fcr_train, aes(x = factor(loan_status), y = loan_amnt)) + 
  geom_boxplot(fill = "orange", alpha = 0.2) +
  ylab("Loan Amount") + xlab("Credit Default") +
  coord_flip() 


grid.arrange(g1, g2, g3, ncol = 1, nrow = 3, top = "Default vs Interest rate, Income and Loan amount")

```

En este último gráfico se compara el riesgo de crédito con tres variables continuas: los tipos de interés, los ingresos anuales y el importe del préstamo. Este gráfico es interesante porque muestra claramente que unos tipos de interés más altos, unos ingresos más bajos y un crédito más elevado aumentan la posibilidad de impago.

# *APLICACIÓN DE LAS TÉCNICAS Y MODELOS DE MACHINE LEARNING*

En esta parte del trabajo, se trata de aplicar diferentes técnicas y algoritmos sobre nuestros datos, de forma que nos lleven a la mejor predición y clasificación posible de la calidad del vino analizado. Para la comparación y selección del mejor algoritmo utilizaremos como métricas de evaluación: “Accuracy”, "Precision", "Recall" y "F1 Score", y trataremos de establecer el mejor punto de corte posible que maximice la misma.

En este apartado se analizan diferentes algoritmos supervisados (aprendizaje supervisado, con datos etiquetados para su predicción o clasificación) sobre nuestro conjunto de datos sobre créditos bancarios.

# 7. GLM - Generalized Lineal Model

## 7.1. Variable de interés y análisis de relaciones entre variables

Primero se crean unos datos de train específicos para ser usados en el desarrollo del modelo GLM, y así mantener los originales sin modificar.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_glm <- fcr_train
fcr_train_glm
```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
table(fcr_train_glm$loan_status)

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
prop.table(table(fcr_train_glm$loan_status))

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
str(fcr_train_glm)

```

Analizando la distinción entre créditos impagados y no impagados, vemos que la distibución entre ambos grupos está poco balanceada, con 20.365 no impagados (78.15%) y 5.694 (21.85%) impagados en los datos de train.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
corrplot(cor(fcr_train_glm %>%
    mutate(loan_status = as.numeric(loan_status)) %>%
    keep(is.numeric)))
```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
res <- cor(fcr_train_glm %>%
    mutate(loan_status = as.numeric(loan_status)) %>%
    keep(is.numeric))
round(res, 2)

```

Analizamos de forma bivariante las variables:

* **Variable loan_int_rate**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_glm %>%
    ggplot(aes(x = loan_int_rate, fill = factor(loan_status))) + geom_density(alpha = 0.5)

```

* **Variable loan_percent_income**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_glm %>%
    ggplot(aes(x = loan_percent_income, fill = factor(loan_status))) + geom_density(alpha = 0.5)

```

En términos generales vemos como los créditos analizados que estan en la categoria de impagados, tienen en general un mayor valor de “loan_int_rate” y de "loan_percent_income".

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_glm %>%
    ggplot(aes(x = cb_person_cred_hist_length, fill = factor(loan_status))) + geom_density(alpha = 0.5)

```

* **Variable loan_amnt**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_glm %>%
    ggplot(aes(x = loan_amnt, fill = factor(loan_status))) + geom_density(alpha = 0.5)

```

* **Variable person_emp_length**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_glm %>%
    ggplot(aes(x = person_emp_length, fill = factor(loan_status))) + geom_density(alpha = 0.5)

```

* **Variable person_age**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_glm %>%
    ggplot(aes(x = person_age, fill = factor(loan_status))) + geom_density(alpha = 0.5)

```

* **Variable person_income**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_glm %>%
    ggplot(aes(x = person_income, fill = factor(loan_status))) + geom_density(alpha = 0.5)

```

En los casos de las variables “cb_person_cred_hist_length”, “loan_amnt”, “person_emp_length”, “person_age” y “person_income”, cuesta más distinguir en el gráfico de densidad entre créditos impagados o no impagados, ya que no son características tan definitivas de un grupo u otro.

## 7.2. Creación del modelo de Regresión Logística

Generamos un modelo de regresión logística en base a las variables de nuestro dataset que sirva como predictor de la variable binaria creada.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
modelo_glm <- glm(loan_status ~ ., data = fcr_train_glm, family = binomial(link = 'logit'))
modelo_glm

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
summary(modelo_glm)

```

Como observamos, nos quedamos solo con las variables significativas que relamente afectan a “loan_status”, y creamos un nuevo modelo exclusivamente con ellas. De esta forma simplificamos el modelo, nos quedamos con las varibales realmente importantes para el modelo predictor y creamos el mejor modelo de regresión logística posible para nuestro conjunto de datos. En principio las variables "cb_person_cred_hist_length", "cb_person_default_on_file" y "person_age", no parecen ser estadisticamente significativas.

Se podría también pensar en la exclusión del modelo, de la variable "loan_percent_income", ya que de forma lógica y como se oberva en las correlaciones, es una variable que viene calculada, relaciona y explicada con las variables "person_income" y "loan_amnt". Esto nos puede llegar a generar multicolinearidad y crear redundancia en los cálculos que hagamos para el modelo.

Finalmente se establece el siguiente modelo definitivo:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
modelo_glm2 <- glm(loan_status ~ person_income + person_emp_length +
            loan_amnt + loan_int_rate + person_home_ownership + loan_intent +
            loan_grade + loan_percent_income, data = fcr_train_glm, family = binomial)
modelo_glm2

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
summary(modelo_glm2)

```

Los residuos de desviación tienen buen aspecto, aunque los valores no están completamente centrados en cero y no son simétricos. Las estimaciones son los parámetros de nuestro interés, mientras que la columna Pr(>|z|) muestra los valores p de dos colas que prueban la hipótesis nula de que el coeficiente es igual a cero. En otras palabras, muestra la importancia de los efectos de cada variable independiente. En nuestro modelo parece que la mayoría de las variables son estadísticamente significativas, sin embargo, para confirmar esta hipótesis procedemos a utilizar la prueba anova, observando la tabla de desviación.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
anova(modelo_glm2, test="Chisq")

```

La diferencia entre la desviación nula y la desviación residual muestra cómo se comporta nuestro modelo frente al modelo nulo, es decir, un modelo con sólo el intercepto. La prueba anova dice que añadir estas variables mejora el modelo de forma significativa, de hecho, los valores p bajos significan que las variables explican una gran parte de la variabilidad.

Ahora se puede analizar el ajuste e interpretar lo que nos dice el modelo. Como se ha analizado, el modelo sugiere que la mayoría de los p-valores muestran relevancia estadística en los resultados. Los únicos que no serían de la categoría HOMEIMPROVEMENT de la variable loan_intent y la categoría OTHER de la variable person_home_ownership, que no son significativos.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
cbind(Estimate=round(coef(modelo_glm2),5),
 OR=round(exp(coef(modelo_glm2)),5))
```

La columna Estimate calculada representa los coeficientes en forma de log-odds. Esto significa que cuando aumentamos la variable loan_int_rate en una unidad, podríamos esperar un cambio en las probabilidades logarítmicas de aproximadamente 0.05570. También podríamos utilizar esta información observando el signo de cada estimación, para entender si el efecto del predictor es positivo o negativo.

Según se puede observar en la tabla calculada, variables numéricas como person_emp_length o loan_amnt disminuyen las probabilidades de default, sin embargo, variables numéricas como loan_int_rate o loan_percent_income las incrementan. 

Las variables categóricas deben interpretarse de forma un poco diferente. En este caso, la estimación representa el cambio en las probabilidades logarítmicas tomando como referencia una categoría base como, por ejemplo, en la regresión person_home_ownership-MORTAGE, loan_intent-DEBTCONSOLIDATION y loan_grade-A. En otras palabras, estar, por ejemplo, en la categoría loan_grade-B aumenta la log-odds de impago en 0.24616, con respecto a estar en loan_grade-A.

Según los resultados que obtenemos, cuando, por ejemplo, el parámetro del tipo de interés (variable loan_int_rate) aumenta una unidad (manteniendo constantes todos los demás predictores), las probabilidades de y = 1 (impago) son 1.05728 más altas o, dicho de otro modo, aumentan aproximadamente un 5.728%. La misma lógica se aplica a todas las demás variables, por lo que, por ejemplo, el aumento de la duración del empleo (variable person_emp_length) en una unidad conduce a una disminución de las probabilidades de impago de 0.98587.

Un elemento a tener en cuenta en el análisis es la variable loan_grade. Se puede observar que a medida que nos acercamos a grados inferiores, las probabilidades de impago aumentan enormemente. Como se dijo posteriormente, las variables categóricas deben interpretarse con respecto a la categoría base, así que en este caso comparando otros niveles con el grado A. Esta variable parece ser muy influyente y se podría decir que la graduación es adecuada y resulta útil para identificar posibles riesgos de impago para prestatarios y prestamistas.

Una interpretación de los coeficientes similar a la realizada sería:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
round(exp(cbind(Estimate = coef(modelo_glm2), confint(modelo_glm2))),2)

```

Los intervalos de confianza no se basan en un test de Wald (como en regresión tradicional), sino en un perfilado (profiling) de la log-likelihood, que es más preciso.

Predicción de valores del modelo:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
head(predict(modelo_glm2))

```

Probabilidad en escala de la salida:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
head(predict(modelo_glm2, type = "response"))

```

A la hora de desarrollar modelos de predicción, la métrica más importante es determinar la eficacia del modelo para predecir la variable objetivo en observaciones fuera de la muestra. Para ello, podemos comparar la variable objetivo predicha con los valores observados mediante la matriz de confusión.

Evaluación del rendimiento predictivo del modelo GLM presentado con las datos de train:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_glm$y_pred_probs <- predict(modelo_glm2, fcr_train_glm, type = "response")
fcr_train_glm$y_pred <- ifelse(fcr_train_glm$y_pred_probs > 0.5, 1, 0)

# fcr_train_glm$y_pred_probs fcr_train_glm$y_pred

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
cm_train <- confusionMatrix(as.factor(fcr_train_glm$y_pred), as.factor(fcr_train_glm$loan_status),
    positive = "1")
cm_train$table

```

La matriz de confusión es una tabla que describe el rendimiento de clasificación de cada modelo en los datos de prueba. En nuestro caso, los "1" y "0" de las filas representan si las personas han incumplido o no, mientras que las columnas "FALSO" y "VERDADERO" indican si predijimos que las personas incumplirían o no. La tabla siguiente sólo muestra las proporciones.

Más concretamente:

* **Verdaderos positivos (cuadrante inferior derecho):** son casos en los que predijimos que la gente incumpliría y lo hizo.
* **Verdaderos negativos (cuadrante superior izquierdo):** Predijimos que no habría impago y la gente no lo hizo.
* **Falsos positivos (cuadrante superior derecho):** Predijimos un impago, pero en realidad no se produjo. (Error de tipo I)
* **Falsos negativos (cuadrante inferior izquierdo):** Predijimos que no habría impago, pero sí lo hubo. (Error de tipo II)

Se utilizan diferentes métricas de evaluación del modelo:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
accuracy_modelo_glm2 <- cm_train$overall["Accuracy"] %>%
    round(4)
accuracy_modelo_glm2

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
recall_modelo_glm2 <- cm_train$byClass["Recall"] %>%
    round(4)
recall_modelo_glm2

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
precision_modelo_glm2 <- cm_train$byClass["Precision"] %>%
    round(4)
precision_modelo_glm2

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
F1Score_modelo_glm2 <- ((2 * precision_modelo_glm2 * recall_modelo_glm2) / (precision_modelo_glm2 + recall_modelo_glm2)) %>%
    round(4)
F1Score_modelo_glm2

```

Viendo el valor de las metricas obtenidas (con un punto de corte en 0.5), el valor de Accuracy (número de predicciones correctas/número total de predicciones) se situa en el 87%, el de Precision (positivos verdaderos/(positivos verdaderos + falsos positivos)) se situa en un 77%, el de Recall o Sensitividad (positivos verdaderos/(positivos verdaderos/falsos negativos)) en un 56% y el F1 Score (considerado como una media armónica que combina los valores de la precisión o precision y de la exhaustividad o recall) en un 65%.

Con estos datos entendemos que con el modelo desarrollado, en alrededor del 87% de los casos este será capaz de predecir si un crédito va a ser impagado o no.

## 7.3. GLM - Cross Validation, Hiperparámetros y Evaluación del modelo

Una vez desarrollado el modelo, se trata de aplicar Cross Validation sobre el modelo de GLM y realizar una selección de hiperparámetros (se busca tener un modelo robusto, generalizable y comparable con el resto para la posterior selección del mejor):

Vemos primero cuales son las posibles variables que tienes el modelo para tratar de configurar. Cómo se puede ver, el modelo GLM no tiene la posibilidad de ajustar hiperparámetros.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
## https://machinelearningmastery.com/how-to-estimate-model-accuracy-in-r-using-the-caret-package/?msclkid=37e9f222aa8711ec9c857e7c4b89d202
## https://daviddalpiaz.github.io/r4sl/the-caret-package.html#classification

# Vemos hiperparámetros que se pueden configurar

modelLookup("glm")

```

Creamos el modelo con las variables seleccionadas como relevantes y haciendo Cross Validation on 5 particiones del dataset de train.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
caret.glm <- train(as.factor(loan_status) ~ person_income + person_emp_length +
            loan_amnt + loan_int_rate + person_home_ownership + loan_intent +
            loan_grade + loan_percent_income, 
                   method = "glm",
                   family = "binomial",
                   data = fcr_train_glm,
                   trControl = trainControl(method = "cv", number = 5, search = "grid",returnResamp = "final"))
caret.glm

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
summary(caret.glm)

```

Con estos datos entendemos que con el modelo desarrollado, en alrededor del 86/87% de los casos este será capaz de predecir si un crédito va a ser impagado o no.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
confusionMatrix(caret.glm)

```

Evaluación del rendimiento predictivo del modelo Decision Tree presentado con las datos de train (metrica de evaluación utilizada de referencia: “Accuracy”, "Recall", "Precision", "F1" y "ROC", y punto de corte utilizado: 0.5):

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_glm$y_pred_probs2 <- predict(caret.glm, fcr_train_glm, type = "prob")
fcr_train_glm$y_pred_probs2 <- ifelse(fcr_train_glm$y_pred_probs2$`1` >
    0.5, fcr_train_glm$y_pred_probs2$`1`, 1 - fcr_train_glm$y_pred_probs2$`0`)
fcr_train_glm$y_pred2 <- ifelse(fcr_train_glm$y_pred_probs2 > 0.5, 1,
    0)

# fcr_train_glm$y_pred_probs2 fcr_train_glm$y_pred2

```

Reproducimos la matriz de confusión y las métricas de evaluación sobre el modelo final de GLM obtenido:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
cm_train2 <- confusionMatrix(as.factor(fcr_train_glm$y_pred2), as.factor(fcr_train_glm$loan_status),
    positive = "1")
cm_train2$table

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
accuracy_modelo_glm2_tune <- cm_train2$overall["Accuracy"] %>%
    round(4)
accuracy_modelo_glm2_tune

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
recall_modelo_glm2_tune <- cm_train2$byClass["Recall"] %>%
    round(4)
recall_modelo_glm2_tune

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
precision_modelo_glm2_tune <- cm_train2$byClass["Precision"] %>%
    round(4)
precision_modelo_glm2_tune

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
F1Score_modelo_glm2_tune <- (2*(precision_modelo_glm2_tune * recall_modelo_glm2_tune) / (precision_modelo_glm2_tune + recall_modelo_glm2_tune)) %>%
    round(4)
F1Score_modelo_glm2_tune

```

Reproducimos la curva ROC sobre el modelo final de GLM obtenido:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
roc_glm <- plot.roc(as.numeric(fcr_train_glm$loan_status), as.numeric(fcr_train_glm$y_pred_probs2),
    col = "blue")
```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
auc(roc_glm)

```

Se obtiene alrededor de un 87% de área bajo la curva.

El ROC es una curva que se genera trazando la tasa de verdaderos positivos (TPR) frente a la tasa de falsos positivos (FPR) en varios umbrales, mientras que el AUC es el área bajo la curva ROC. Dicho de otro modo, el ROC traza el porcentaje de verdaderos positivos predichos con exactitud por el modelo a medida que el umbral de probabilidad de predicción se reduce de 1 a 0. Muestra la compensación entre la tasa a la que se puede predecir correctamente algo con la tasa de predecir incorrectamente algo.

Por lo tanto, para un buen modelo, la curva debería aumentar de forma pronunciada, indicando que el TPR (eje Y) aumenta más rápido que el FPR (eje X) a medida que disminuye la puntuación de corte. Cuanto mayor sea el área bajo la curva ROC, mejor será la capacidad predictiva del modelo. Esa métrica oscila entre 0,50 y 1,00, y los valores superiores a 0,80 indican que el modelo hace un buen trabajo al discriminar entre las dos categorías que componen nuestra variable objetivo.

# 8. DECISION TREE

Primero se crean unos datos de train específicos para ser usados en el desarrollo del modelo de árbol de decisión, y así mantener los originales sin modificar.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_tree <- fcr_train
fcr_train_tree

```

Se crea un modelo de árbol de decisión inicial básico y sin podar utilizando las 11 variables predictoras que tenemos a nuestra disposición y utilizando el método de “Gini” como medida de la impureza:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# árbol de clasificación con las opciones por defecto (cp = 0.0001 y split = "gini") con el comando:
tree = rpart(as.factor(loan_status) ~ ., data = fcr_train_tree, cp=0.0001)
rpart.plot(tree, nn = TRUE, extra = 104,  box.palette = "GnBu", branch.lty = 3, shadow.col = "gray")

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
tree

```

Analizamos los resultados obtenidos de forma numérica:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
rpart.rules(tree, style = "tall")

```

* **Modelo Decision Tree sin poda:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
obs_tree1 <- as.factor(fcr_train_tree$loan_status)
head(predict(tree, newdata = fcr_train_tree))

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
pred_tree1 <- predict(tree, newdata = fcr_train_tree, type = "class")
table(obs_tree1, pred_tree1)

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
caret::confusionMatrix(pred_tree1, obs_tree1)

```

Se obtiene un valor del 94.31% para la precisión del modelo, con el incoveniente de tener un modelo sin poda, demasiado complejo y que puede tender al sobreajuste.

Se realiza por ello la valoración para una posible poda del modelo que permita simplificarlo y hacerlo más explicativo sin perder capacidad predictora. Para ello vemos el CP o “Parámetro de complejidad” con el cual buscamos el árbol menos profundo que además minimice la tasa de error.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
plotcp(tree) 
#CP - PARÁMETRO DE COMPLEJIDAD: Buscamos el árbol menos profundo que además minimiza la tasa de error

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
printcp(tree)

```

Finalmente decimos proceder a realizar la poda y crear un modelo alternativo más simplificado:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
xerror <- tree$cptable[, "xerror"]
imin.xerror <- which.min(xerror)
upper.xerror <- xerror[imin.xerror] + tree$cptable[imin.xerror,
    "xstd"]
icp <- min(which(xerror <= upper.xerror))
cp <- tree$cptable[icp, "CP"]
cp
```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
tree_2 <- prune(tree, cp = cp)
# tree summary(tree) caret::varImp(tree) importance <-
# tree$variable.importance importance <-
# round(100*importance/sum(importance), 1)
# importance[importance >= 1]
rpart.plot(tree_2, nn = TRUE, extra = 104, box.palette = "GnBu",
    branch.lty = 3, shadow.col = "gray")  #, main='Classification tree winetaste'

```

* **Modelo Decision Tree con poda:**

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
obs_tree2 <- as.factor(fcr_train_tree$loan_status)
head(predict(tree_2, newdata = fcr_train_tree))

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
pred_tree2 <- predict(tree_2, newdata = fcr_train_tree, type = "class")
table(obs_tree2, pred_tree2)

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
caret::confusionMatrix(pred_tree2, obs_tree2)

```

Aplicando la poda a nuestro árbol obtenemos un modelo mas limpio, simple, explicativo y generalizable a otro conjunto de datos, evitando el posible sobreajuste del modelo y solo reduciendo su capacidad predictora a un valor de precisión del 93.08%. Entendemos que este modelo podado será el óptimo en este caso.

## 8.1. DECISION TREE - Cross Validation, Hiperparámetros y Evaluación del modelo

Tratamos de aplicar Cross Validation sobre el modelo de árbol de decisión y realizar una selección de hiperparámetros (se busca tener un modelo robusto, generalizable y comparable con el resto para la posterior selección del mejor):

De cara a obtener el mejor modelo posible realizaremos validación cruzada de 5 folds y trataremos de ajustar hiperparámetros (el “cp” óptimo para un modelo ya validado). Utilizamos además las variables que hemos vito como más representativas y explicativas de la variable respuesta “loan_status”.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# Fit the model on the training set
set.seed(1234)
caret.tree <- train(as.factor(loan_status) ~ person_income + person_emp_length +
            loan_amnt + loan_int_rate + person_home_ownership + loan_intent +
            loan_grade + loan_percent_income,  data = fcr_train_tree,
    method = "rpart", trControl = trainControl("cv", number = 5,
        search = "grid", returnResamp = "final"), tuneLength = 20)
# Plot model accuracy vs different values of cp (complexity
# parameter)
plot(caret.tree)

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
caret.tree

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
caret.tree$bestTune

```

Realizando la validación cruzada vemos que el CP óptimo para nuestro modelo de árbol de decisión se encuentra en 0.0008781173.

Visualizamos graficamente el árbol obtenido:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# Plot the final tree model
par(xpd = NA) # Avoid clipping the text in some device
plot(caret.tree$finalModel,uniform=TRUE)
text(caret.tree$finalModel,  digits = 10)

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
get_best_result = function(caret_fit) {
    best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
    best_result = caret_fit$results[best, ]
    rownames(best_result) = NULL
    best_result
}

get_best_result(caret.tree)

```

Obtenemos finalmente haciendo validación cruzada una precisión del 92/93%, con un modelo que ha sido comprobado como robusto y generalizable para funcionar previsiblemente en otro conjunto de datos diferente.

Evaluación del rendimiento predictivo del modelo Decision Tree presentado con las datos de train (metrica de evaluación utilizada de referencia: “Accuracy”, "Recall", "Precision", "F1" y "ROC", y punto de corte utilizado: 0.5):

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_tree$y_pred_probs2 <- predict(caret.tree, newdata = fcr_train_tree,
    type = "prob")
fcr_train_tree$y_pred_probs2 <- ifelse(fcr_train_tree$y_pred_probs2$`1` >
    0.5, fcr_train_tree$y_pred_probs2$`1`, 1 - fcr_train_tree$y_pred_probs2$`0`)

fcr_train_tree$y_pred2 <- ifelse(fcr_train_tree$y_pred_probs2 > 0.5,
    1, 0)

# fcr_train_tree$y_pred_probs2 fcr_train_tree$y_pred2
```

Reproducimos la matriz de confusión y las métricas de evaluación sobre el modelo final de Decision Tree obtenido:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
cm_train_tree <- confusionMatrix(as.factor(fcr_train_tree$y_pred2),
    as.factor(fcr_train_tree$loan_status), positive = "1")
cm_train_tree$table
```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
accuracy_modelo_tree_tune <- cm_train_tree$overall["Accuracy"] %>%
    round(4)
accuracy_modelo_tree_tune

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
recall_modelo_tree_tune <- cm_train_tree$byClass["Recall"] %>%
    round(4)
recall_modelo_tree_tune

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
precision_modelo_tree_tune <- cm_train_tree$byClass["Precision"] %>%
    round(4)
precision_modelo_tree_tune

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
F1Score_modelo_tree_tune <- (2*(precision_modelo_tree_tune * recall_modelo_tree_tune) / (precision_modelo_tree_tune + recall_modelo_tree_tune)) %>%
    round(4)
F1Score_modelo_tree_tune

```

Reproducimos la curva ROC sobre el modelo final de árbol de decisión obtenido:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
roc_tree <- plot.roc(as.numeric(fcr_train_tree$loan_status), as.numeric(fcr_train_tree$y_pred_probs2),
    col = "yellow")
```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
auc(roc_tree)

```

Se obtiene alrededor de un 88.29% de área bajo la curva.

# 9. RANDOM FOREST

Primero se crean unos datos de train específicos para ser usados en el desarrollo del modelo de random forest, y así mantener los originales sin modificar.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_forest <- fcr_train
fcr_train_forest

```

Creamos el modelo base de random forest realizando una simulación con 1000 árboles:

```{r, include=TRUE, message=FALSE, include=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
set.seed(4343)
rf <-randomForest(as.factor(loan_status)~., data=fcr_train_forest, ntree=1000, do.trace=T, importance=T)
rf

```  

Examinamos la convergencia del error en las muestras:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
plot(rf,main="")
legend("right", colnames(rf$err.rate), lty = 1:5, col = 1:6)

```

Vemos la relevancia de las variables en el modelo:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
varImpPlot(rf)

```

## 9.1. RANDOM FOREST - Cross Validation, Hiperparámetros y Evaluación del modelo

Tratamos de aplicar Cross Validation sobre el modelo de random forest y realizar una selección de hiperparámetros (se busca tener un modelo robusto, generalizable y comparable con el resto para la posterior selección del mejor):

Vemos que el principal parámetro a configurar es el número de predictores al azar que toma el modelo.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
modelLookup("rf")

```

Creamos un modelo aplicando la validación cruzada y ajustando hiperparámetros (mtry, número de árboles y el tamaño de los nodos para regular su profundidad) de tal forma que creemos un modelo robusto y generalizable. Tomamos como base las variables de mayor relevancia que hemos observado:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# Fit the model on the training set
set.seed(12345)

caret.rf <- train(as.factor(loan_status) ~ loan_percent_income + person_income + loan_grade + person_home_ownership ,  data = fcr_train_forest,
    method = "rf", ntree = 20, importance = TRUE, metric = "Accuracy",
    trControl = trainControl("cv", number = 5, search = "grid",
        returnResamp = "final"), nodesize = 30, tuneLength = 10)

plot(caret.rf)

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
caret.rf

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
caret.rf$bestTune

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
get_best_result = function(caret_fit) {
    best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
    best_result = caret_fit$results[best, ]
    rownames(best_result) = NULL
    best_result
}

get_best_result(caret.rf)
```

Evaluación del rendimiento predictivo del modelo Decision Tree presentado con las datos de train (metrica de evaluación utilizada de referencia: “Accuracy”, "Recall", "Precision", "F1" y "ROC", y punto de corte utilizado: 0.5):

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_forest$y_pred_probs2 <- predict(caret.rf, newdata = fcr_train_forest,
    type = "prob")
fcr_train_forest$y_pred_probs2 <- ifelse(fcr_train_forest$y_pred_probs2$`1` >
    0.5, fcr_train_forest$y_pred_probs2$`1`, 1 - fcr_train_forest$y_pred_probs2$`0`)

fcr_train_forest$y_pred2 <- ifelse(fcr_train_forest$y_pred_probs2 > 0.5,
    1, 0)

# fcr_train_forest$y_pred_probs2 fcr_train_forest$y_pred2
# fcr_train_forest
```

Reproducimos la matriz de confusión y las métricas de evaluación sobre el modelo final de Decision Tree obtenido:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
cm_train_forest <- confusionMatrix(as.factor(fcr_train_forest$y_pred2),
    as.factor(fcr_train_forest$loan_status), positive = "1")
cm_train_forest$table

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
accuracy_modelo_forest_tune <- cm_train_forest$overall["Accuracy"] %>%
    round(4)
accuracy_modelo_forest_tune

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
recall_modelo_forest_tune <- cm_train_forest$byClass["Recall"] %>%
    round(4)
recall_modelo_forest_tune

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
precision_modelo_forest_tune <- cm_train_forest$byClass["Precision"] %>%
    round(4)
precision_modelo_forest_tune

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
F1Score_modelo_forest_tune <- (2*(precision_modelo_forest_tune * recall_modelo_forest_tune) / (precision_modelo_forest_tune + recall_modelo_forest_tune)) %>%
    round(4)
F1Score_modelo_forest_tune

```

Reproducimos la curva ROC sobre el modelo final de random forest obtenido:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
roc_forest <- plot.roc(as.numeric(fcr_train_forest$loan_status), as.numeric(fcr_train_forest$y_pred_probs2),
    col = "red")
```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
auc(roc_forest)

```

Se obtiene alrededor de un 94.73% de área bajo la curva.

# 10. ADABoost - Boosted Classification Tree

Primero se crean unos datos de train específicos para ser usados en el desarrollo del modelo de ADABoost, y así mantener los originales sin modificar.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_ADABoost <- fcr_train
fcr_train_ADABoost

```

Creamos el modelo de boosting con una configuración inicial básica de parámetros:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
ada.boost <- ada(as.factor(loan_status) ~ ., data = fcr_train_ADABoost, type = "real",
             control = rpart.control(maxdepth = 2, cp = 0, minsplit = 10, xval = 0),
             iter = 150, nu = 0.05)
ada.boost
```

Se analiza la evolución decreciente del error al aumentar el número de iteraciones en el modelo

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
plot(ada.boost)

```

Se pasa a evaluar la precisión del modelo en la muestra de train:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
set.seed(123)
pred_ada <- predict(ada.boost, newdata = fcr_train_ADABoost)
caret::confusionMatrix(pred_ada, as.factor(fcr_train_ADABoost$loan_status), positive = "1")

```

Con la configuración de parámetros realizada en el modelo ada de booting se obtiene un valor de accuracy del 92% para el caso de algoritmos de clasificación.

Para optimizar los resultados del modelo creado y la generalización del modelo, se puede realizar un ajuste de hiperparámetros y validación cruzada:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
modelLookup("ada")

```

Se ven los parámetros de “iter”, “maxdepth” y “nu” que tiene el modelo ada de boosting para árboles de decisión en problemas de clasificación.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
set.seed(123)
caret.ada <- train(as.factor(loan_status) ~ ., method = "ada", data = fcr_train_ADABoost,
                   trControl = trainControl(method = "cv", number = 5, search = "grid",returnResamp = "final"))
caret.ada

```

Obtenemos una configuración óptima de los hiperparámetros del modelo en “iter” = 150, “maxdepth” = 3 y “nu” = 0.1.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
caret.ada

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
caret.ada$bestTune

```

Con el modelo de base obtenemos un accuracy del 90% con los datos de train.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
get_best_result = function(caret_fit) {
    best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
    best_result = caret_fit$results[best, ]
    rownames(best_result) = NULL
    best_result
}

get_best_result(caret.ada)
```

Evaluación del rendimiento predictivo del modelo Ada Boost presentado con las datos de train (metrica de evaluación utilizada de referencia: “Accuracy”, "Recall", "Precision", "F1" y "ROC", y punto de corte utilizado: 0.5):

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_ADABoost$y_pred_probs2 <- predict(caret.ada, newdata = fcr_train_ADABoost,
    type = "prob")
fcr_train_ADABoost$y_pred_probs2 <- ifelse(fcr_train_ADABoost$y_pred_probs2$`1` >
    0.5, fcr_train_ADABoost$y_pred_probs2$`1`, 1 - fcr_train_ADABoost$y_pred_probs2$`0`)

fcr_train_ADABoost$y_pred2 <- ifelse(fcr_train_ADABoost$y_pred_probs2 > 0.5, 1, 0)

# fcr_train_ADABoost$y_pred_probs2 fcr_train_ADABoost$y_pred2 fcr_train_ADABoost
```

Reproducimos la matriz de confusión y las métricas de evaluación sobre el modelo final de Decision Tree obtenido:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
cm_train_ada <- confusionMatrix(as.factor(fcr_train_ADABoost$y_pred2), as.factor(fcr_train_ADABoost$loan_status),
    positive = "1")
cm_train_ada$table

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
accuracy_modelo_ada_tune <- cm_train_ada$overall["Accuracy"] %>%
    round(4)
accuracy_modelo_ada_tune

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
recall_modelo_ada_tune <- cm_train_ada$byClass["Recall"] %>%
    round(4)
recall_modelo_ada_tune

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
precision_modelo_ada_tune <- cm_train_ada$byClass["Precision"] %>%
    round(4)
precision_modelo_ada_tune

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
F1Score_modelo_ada_tune <- (2*(precision_modelo_ada_tune * recall_modelo_ada_tune) / (precision_modelo_ada_tune + recall_modelo_ada_tune)) %>%
    round(4)
F1Score_modelo_ada_tune

```

Reproducimos la curva ROC sobre el modelo final de ADABoost obtenido:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
roc_ada <- plot.roc(as.numeric(fcr_train_ADABoost$loan_status), as.numeric(fcr_train_ADABoost$y_pred_probs2),
    col = "orange")
```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
auc(roc_ada)

```

Se obtiene alrededor de un 91.69% de área bajo la curva.

# 11. XGBoost - Extreme Gradient Boosting

Primero se crean unos datos de train específicos para ser usados en el desarrollo del modelo de ADABoost, y así mantener los originales sin modificar.

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_XGBoost <- fcr_train
fcr_train_XGBoost

```

Para optimizar los resultados del modelo creado, se puede realizar un ajuste de hiperparámetros con validación cruzada:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
modelLookup("xgbTree")

```

Creamos el modelo de boosting con una configuración inicial dada de parámetros:

```{r, include=FALSE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
set.seed(2)
caret.xgb <- train(as.factor(loan_status) ~ ., 
                   method = "xgbTree", 
                   data = fcr_train_XGBoost,
                   trControl = trainControl(method = "cv", number = 5, search = "grid", returnResamp = "final"))
caret.xgb

```  

Obtenemos una configuración óptima de los hiperparámetros del modelo en:

```{r, include=FALSE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
get_best_result = function(caret_fit) {
    best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
    best_result = caret_fit$results[best, ]
    rownames(best_result) = NULL
    best_result
}

get_best_result(caret.xgb)

```  

Se analiza la relevancia de cada variable en el modelo:

```{r, include=FALSE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
varImp(caret.xgb)

```  

Evaluación del rendimiento predictivo del modelo Ada Boost presentado con las datos de train (metrica de evaluación utilizada de referencia: “Accuracy”, "Recall", "Precision", "F1" y "ROC", y punto de corte utilizado: 0.5):

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
fcr_train_XGBoost$y_pred_probs2 <- predict(caret.xgb, newdata = fcr_train_XGBoost,
    type = "prob")
fcr_train_XGBoost$y_pred_probs2 <- ifelse(fcr_train_XGBoost$y_pred_probs2$`1` >
    0.5, fcr_train_XGBoost$y_pred_probs2$`1`, 1 - fcr_train_XGBoost$y_pred_probs2$`0`)

fcr_train_XGBoost$y_pred2 <- ifelse(fcr_train_XGBoost$y_pred_probs2 > 0.5, 1,
    0)

# fcr_train_XGBoost$y_pred_probs2 fcr_train_XGBoost$y_pred2 fcr_train_XGBoost
```

Reproducimos la matriz de confusión y las métricas de evaluación sobre el modelo final de Decision Tree obtenido:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
cm_train_xgb <- confusionMatrix(as.factor(fcr_train_XGBoost$y_pred2), as.factor(fcr_train_XGBoost$loan_status),
    positive = "1")
cm_train_xgb$table

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
accuracy_modelo_xgb_tune <- cm_train_xgb$overall["Accuracy"] %>%
    round(4)
accuracy_modelo_xgb_tune

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
recall_modelo_xgb_tune <- cm_train_xgb$byClass["Recall"] %>%
    round(4)
recall_modelo_xgb_tune

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
precision_modelo_xgb_tune <- cm_train_xgb$byClass["Precision"] %>%
    round(4)
precision_modelo_xgb_tune

```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
# result
F1Score_modelo_xgb_tune <- (2*(precision_modelo_xgb_tune * recall_modelo_xgb_tune) / (precision_modelo_xgb_tune + recall_modelo_xgb_tune)) %>%
    round(4)
F1Score_modelo_xgb_tune

```

Reproducimos la curva ROC sobre el modelo final de XGBoost obtenido:

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
roc_xgb <- plot.roc(as.numeric(fcr_train_XGBoost$loan_status), as.numeric(fcr_train_XGBoost$y_pred_probs2),
    col = "purple")
```

```{r, include=TRUE, message=FALSE, warning = FALSE,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
auc(roc_xgb)

```

Se obtiene alrededor de un 96.54% de área bajo la curva.

# *COMPARACIÓN DE LAS TÉCNICAS Y MODELOS DE MACHINE LEARNING*









